import os
import requests
import zipfile
import xml.etree.ElementTree as ET
import pandas as pd
import schedule
import time
from datetime import datetime

# Set parameters
download_urls = [
    "https://example.com/path/to/bulk_extract_part1.zip",  # Replace with the first URL
    "https://example.com/path/to/bulk_extract_part2.zip"   # Replace with the second URL
]
download_folder = "bulk_extracts"  # Folder to store downloaded zip files
extract_folder = "extracted_data"  # Folder to store extracted XML files
database_file = "abn_database.csv"  # Offline database file

# Create necessary directories
os.makedirs(download_folder, exist_ok=True)
os.makedirs(extract_folder, exist_ok=True)

# Function to download bulk extract files
def download_bulk_extract():
    print(f"Starting file download - {datetime.now()}")
    for url in download_urls:
        file_name = os.path.join(download_folder, url.split("/")[-1])
        response = requests.get(url, stream=True)
        with open(file_name, "wb") as file:
            for chunk in response.iter_content(chunk_size=1024):
                if chunk:
                    file.write(chunk)
        print(f"Downloaded: {file_name}")
    print("File download completed")

# Function to extract zip files
def extract_files():
    print(f"Starting file extraction - {datetime.now()}")
    for file_name in os.listdir(download_folder):
        if file_name.endswith(".zip"):
            zip_path = os.path.join(download_folder, file_name)
            with zipfile.ZipFile(zip_path, "r") as zip_ref:
                zip_ref.extractall(extract_folder)
            print(f"Extracted: {file_name}")
    print("Extraction completed")

# Function to parse XML files and update the database
def update_database():
    print(f"Starting database update - {datetime.now()}")
    records = []

    for file_name in os.listdir(extract_folder):
        if file_name.endswith(".xml"):
            file_path = os.path.join(extract_folder, file_name)
            context = ET.iterparse(file_path, events=("start", "end"))
            context = iter(context)

            for event, elem in context:
                if event == "end" and elem.tag == "ABR":  # Assuming each record is <ABR>
                    record = {
                        "ABN": elem.findtext("ABN"),
                        "EntityType": elem.findtext("EntityType/EntityTypeText"),
                        "State": elem.findtext("BusinessAddress/AddressDetails/State"),
                        "Postcode": elem.findtext("BusinessAddress/AddressDetails/Postcode"),
                        "GSTStatus": elem.find("GST").get("status") if elem.find("GST") is not None else None,
                        "GSTStatusFromDate": elem.find("GST").get("GSTStatusFromDate") if elem.find("GST") is not None else None,
                    }
                    records.append(record)
                    elem.clear()

    # Save results to CSV
    df = pd.DataFrame(records)
    df.to_csv(database_file, index=False)
    print("Database update completed")

# Function to query a single ABN
def query_abn(abn):
    if not os.path.exists(database_file):
        print("Database does not exist. Please update the database first.")
        return
    df = pd.read_csv(database_file)
    result = df[df["ABN"] == abn]
    return result if not result.empty else None

# Function to batch query ABNs
def batch_query_abns(abn_list, output_file="batch_query_results.csv"):
    if not os.path.exists(database_file):
        print("Database does not exist. Please update the database first.")
        return
    df = pd.read_csv(database_file)
    results = df[df["ABN"].isin(abn_list)]
    results.to_csv(output_file, index=False)
    print(f"Batch query completed. Results saved to {output_file}")

# Function to load ABN list from an XLSX file
def load_abn_list_from_xlsx(file_path):
    abn_list = pd.read_excel(file_path)["ABN"].astype(str).tolist()
    print(f"Loaded {len(abn_list)} ABNs from {file_path}")
    return abn_list

# Function to automate tasks
def scheduled_task():
    download_bulk_extract()
    extract_files()
    update_database()

# Schedule weekly task
schedule.every().week.at("02:00").do(scheduled_task)  # Run every week at 2:00 AM

# Main loop
if __name__ == "__main__":
    print("Offline ABN Query System Started")
    
    # Example usage:
    # Update the database
    # scheduled_task()
    
    # Perform a batch query
    abn_list = load_abn_list_from_xlsx("abn_list.xlsx")  # Replace with your file path
    batch_query_abns(abn_list, output_file="batch_query_results.csv")
    
    # Start the scheduler
    while True:
        schedule.run_pending()
        time.sleep(1)
